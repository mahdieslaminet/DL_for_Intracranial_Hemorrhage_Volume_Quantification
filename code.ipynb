{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSqkE+cZ50HcMDNFChF0qy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Explanation of the Code\n","Data Loading and Preparation:\n","\n","load_dataset() function loads images and corresponding labels from the specified directory.\n","Images are resized to 256x256 pixels and normalized to the range [0, 1].\n","Data Augmentation:\n","\n","Data augmentation is applied using ImageDataGenerator to improve the robustness of the model.\n","Model Building:\n","\n","A Hybrid CNN-LSTM model is built using DenseNet-121 as the CNN backbone and an LSTM layer for capturing temporal dependencies.\n","The model outputs the hemorrhage volume as a regression task.\n","Model Training:\n","\n","The model is compiled with the Adam optimizer and mean squared error loss function.\n","Training is performed with early stopping and model checkpointing to avoid overfitting.\n","Model Evaluation:\n","\n","After training, the model is evaluated on the test set.\n","Mean Squared Error (MSE) and Mean Absolute Error (MAE) are calculated to assess the performance.\n","Make sure to replace 'path/to/images' and 'path/to/labels.csv' with the actual paths to your dataset. This code is designed to run in Google Colab, but it should work in any Python environment with the necessary libraries installed."],"metadata":{"id":"LOU9Itxd1zSx"}},{"cell_type":"code","source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, LSTM, TimeDistributed, Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score, confusion_matrix, classification_report\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from glob import glob\n","\n","# Constants\n","IMAGE_SIZE = 256\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","LEARNING_RATE = 0.001\n","\n","# Load the dataset\n","# Assuming dataset is downloaded and available in the current working directory\n","def load_dataset(image_dir, label_file):\n","    images = []\n","    labels = pd.read_csv(label_file)\n","\n","    for idx, row in labels.iterrows():\n","        image_path = os.path.join(image_dir, row['filename'])\n","        if os.path.exists(image_path):\n","            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n","            images.append(img)\n","        else:\n","            print(f\"Image {image_path} not found!\")\n","\n","    images = np.array(images).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n","    labels = labels.drop(columns=['filename']).values\n","\n","    return images, labels\n","\n","# Preprocess the dataset\n","def preprocess_images(images):\n","    # Normalization\n","    images = images / 255.0\n","    return images\n","\n","# Data augmentation\n","def augment_data(images, labels):\n","    datagen = ImageDataGenerator(rotation_range=20,\n","                                 width_shift_range=0.2,\n","                                 height_shift_range=0.2,\n","                                 horizontal_flip=True)\n","    datagen.fit(images)\n","    return datagen\n","\n","# Load and preprocess dataset\n","image_dir = 'path/to/images'\n","label_file = 'path/to/labels.csv'\n","images, labels = load_dataset(image_dir, label_file)\n","images = preprocess_images(images)\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Augment the training data\n","datagen = augment_data(X_train, y_train)\n","\n","# Build the Hybrid CNN-LSTM Model\n","def build_model(input_shape):\n","    input_layer = Input(shape=input_shape)\n","\n","    # CNN Backbone (DenseNet121)\n","    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_layer)\n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dropout(0.5)(x)\n","    cnn_output = Dense(256, activation='relu')(x)\n","\n","    # Reshape for LSTM\n","    lstm_input = tf.reshape(cnn_output, [-1, 1, 256])\n","\n","    # LSTM Layer\n","    lstm_output = LSTM(128, return_sequences=False)(lstm_input)\n","\n","    # Output Layer (Regression for volume quantification)\n","    output_layer = Dense(1, activation='linear')(lstm_output)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","\n","    return model\n","\n","model = build_model((IMAGE_SIZE, IMAGE_SIZE, 1))\n","model.summary()\n","\n","# Compile the model\n","optimizer = Adam(lr=LEARNING_RATE)\n","model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n","\n","# Callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n","\n","# Train the model\n","history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n","                    steps_per_epoch=len(X_train) // BATCH_SIZE,\n","                    validation_data=(X_val, y_val),\n","                    epochs=EPOCHS,\n","                    callbacks=[early_stopping, model_checkpoint])\n","\n","# Evaluate the model\n","model.load_weights('best_model.h5')\n","y_pred = model.predict(X_test)\n","\n","# Calculate evaluation metrics\n","mse = np.mean((y_test - y_pred)**2)\n","mae = np.mean(np.abs(y_test - y_pred))\n","\n","print(f\"Mean Squared Error: {mse}\")\n","print(f\"Mean Absolute Error: {mae}\")\n","\n","# Visualization\n","plt.plot(history.history['loss'], label='train_loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Evaluate classification performance\n","# Assuming classification labels are available in the dataset\n","# Convert regression outputs to binary classification\n","y_pred_class = np.where(y_pred > 0.5, 1, 0)\n","accuracy = accuracy_score(y_test, y_pred_class)\n","precision = precision_score(y_test, y_pred_class)\n","recall = recall_score(y_test, y_pred_class)\n","roc_auc = roc_auc_score(y_test, y_pred)\n","average_precision = average_precision_score(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"ROC-AUC: {roc_auc}\")\n","print(f\"Average Precision: {average_precision}\")\n","\n","# Confusion matrix and classification report\n","cm = confusion_matrix(y_test, y_pred_class)\n","cr = classification_report(y_test, y_pred_class)\n","\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Classification Report:\")\n","print(cr)\n","\n","# Plot ROC curve\n","fpr, tpr, _ = roc_curve(y_test, y_pred)\n","plt.figure()\n","plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Plot Precision-Recall curve\n","precision, recall, _ = precision_recall_curve(y_test, y_pred)\n","plt.figure()\n","plt.plot(recall, precision, color='blue', lw=2, label='PR curve (area = %0.2f)' % average_precision)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend(loc=\"lower left\")\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"CPH-pO6P12Sv","executionInfo":{"status":"error","timestamp":1721306449456,"user_tz":-210,"elapsed":17368,"user":{"displayName":"niloofar farahani","userId":"02655302324634087475"}},"outputId":"70f89c14-f63d-45d0-b4c6-ddb67419b405"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'path/to/labels.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d6e566d48a66>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/labels.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-d6e566d48a66>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(image_dir, label_file)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/labels.csv'"]}]}]}